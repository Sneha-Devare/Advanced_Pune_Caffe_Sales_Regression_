{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8c1da2-b171-455a-9727-2b008bef03a6",
   "metadata": {},
   "source": [
    "## **Advanced Pune Caffe Sales(Year 2000) Regression Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7a72e4-81e9-44a8-975b-534c0ac7357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd     # for data cleaning, filtering and manipulation\n",
    "import numpy as np           # numpy used for numerical computing\n",
    "import seaborn as sns           # for advance and beautiful visualizations\n",
    "import matplotlib.pyplot as plt     # for creating visualizations\n",
    "%matplotlib inline \n",
    "from ydata_profiling import ProfileReport     # for generating profile report     \n",
    "import plotly.express as px         # interactive and web based plotting library in python\n",
    "import warnings                 # for supressing warning messages during code execution\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)   # for displaying all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44365d81-bf89-470e-8e7c-2a32a6c19050",
   "metadata": {},
   "source": [
    "#### **Necessary Libraries**\n",
    "- **`Pandas`** - Pandas is used for data analysis and handling tabular data like Excel.\n",
    "It provides easy tools to load, clean, and explore data using DataFrames.\n",
    "- **`Numpy`** - NumPy is a Python library used for fast mathematical and array operations.\n",
    "It helps in working with large datasets using arrays, matrices, and functions.\n",
    "- **`Seaborn`** - Seaborn is a Python library for making beautiful and simple statistical charts.\n",
    "It is built on top of Matplotlib and works well with Pandas.\n",
    "- **`Matplotlib`** - Matplotlib is used to create basic graphs like line, bar, and pie charts.\n",
    "It helps in visualizing data in static and simple formats.\n",
    "- **`Plotly`** - Plotly is a library for creating interactive and web-based charts.\n",
    "It is used when you want zoomable and clickable graphs.\n",
    "- **`%matplotlib inline`** - This is used in Jupyter Notebook to show plots right below your code cell.\n",
    "It helps display Matplotlib charts inside the notebook.\n",
    "warnings (import warnings)\n",
    "- **`import warnings`** - import warnings is used to manage or ignore warning messages in Python.\n",
    "It helps keep output clean and readable during code execution.\n",
    "- **`ydata_profiling`** - ydata_profiling quickly creates an automatic EDA report from your data.\n",
    "It gives summaries, graphs, and insights in one HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2d10b4-5ca7-4d8b-ac9e-aa4942ff1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset using .read_csv() method of pandas\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\Advanced_Pune_Cafe_Sales_2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b15c633-d7ee-4380-8393-f4e63c71f838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>outlet_location</th>\n",
       "      <th>outlet_manager</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_name</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>price_per_unit</th>\n",
       "      <th>total_bill</th>\n",
       "      <th>cost_price</th>\n",
       "      <th>profit</th>\n",
       "      <th>payment_mode</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temperature_c</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>final_amount</th>\n",
       "      <th>special_event</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>day_type</th>\n",
       "      <th>cumulative_sales_outlet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD51036</td>\n",
       "      <td>2025-10-19</td>\n",
       "      <td>Hinjewadi</td>\n",
       "      <td>Priya Nair</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Cheese Garlic Bread</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>980</td>\n",
       "      <td>771.03</td>\n",
       "      <td>208.97</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Morning</td>\n",
       "      <td>34.9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3.1</td>\n",
       "      <td>15</td>\n",
       "      <td>833.00</td>\n",
       "      <td>Weekend Special</td>\n",
       "      <td>ST11</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>833.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD94971</td>\n",
       "      <td>2025-10-09</td>\n",
       "      <td>Kothrud</td>\n",
       "      <td>Arjun Mehta</td>\n",
       "      <td>Tourist</td>\n",
       "      <td>Beverage</td>\n",
       "      <td>Cappuccino</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>402</td>\n",
       "      <td>267.03</td>\n",
       "      <td>134.97</td>\n",
       "      <td>Card</td>\n",
       "      <td>Evening</td>\n",
       "      <td>25.3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>402.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>402.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD82709</td>\n",
       "      <td>2025-10-07</td>\n",
       "      <td>Viman Nagar</td>\n",
       "      <td>Rohit Deshmukh</td>\n",
       "      <td>Tourist</td>\n",
       "      <td>Beverage</td>\n",
       "      <td>Green Tea</td>\n",
       "      <td>3</td>\n",
       "      <td>243</td>\n",
       "      <td>729</td>\n",
       "      <td>519.16</td>\n",
       "      <td>209.84</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Evening</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5</td>\n",
       "      <td>692.55</td>\n",
       "      <td>Weekend Special</td>\n",
       "      <td>ST22</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>692.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD61541</td>\n",
       "      <td>2025-10-22</td>\n",
       "      <td>Viman Nagar</td>\n",
       "      <td>Rohit Deshmukh</td>\n",
       "      <td>Tourist</td>\n",
       "      <td>Beverage</td>\n",
       "      <td>Cappuccino</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>105.44</td>\n",
       "      <td>68.56</td>\n",
       "      <td>Card</td>\n",
       "      <td>Evening</td>\n",
       "      <td>25.7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>174.00</td>\n",
       "      <td>Diwali Offer</td>\n",
       "      <td>ST22</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>866.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD20674</td>\n",
       "      <td>2025-10-07</td>\n",
       "      <td>Kothrud</td>\n",
       "      <td>Arjun Mehta</td>\n",
       "      <td>New</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Cheesecake</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>700</td>\n",
       "      <td>559.49</td>\n",
       "      <td>140.51</td>\n",
       "      <td>Card</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>26.8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4.4</td>\n",
       "      <td>15</td>\n",
       "      <td>595.00</td>\n",
       "      <td>Coffee Fest</td>\n",
       "      <td>ST4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>997.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id        date outlet_location  outlet_manager customer_type  \\\n",
       "0  ORD51036  2025-10-19       Hinjewadi      Priya Nair       Regular   \n",
       "1  ORD94971  2025-10-09         Kothrud     Arjun Mehta       Tourist   \n",
       "2  ORD82709  2025-10-07     Viman Nagar  Rohit Deshmukh       Tourist   \n",
       "3  ORD61541  2025-10-22     Viman Nagar  Rohit Deshmukh       Tourist   \n",
       "4  ORD20674  2025-10-07         Kothrud     Arjun Mehta           New   \n",
       "\n",
       "  item_category            item_name  quantity_sold  price_per_unit  \\\n",
       "0         Snack  Cheese Garlic Bread              4             245   \n",
       "1      Beverage           Cappuccino              3             134   \n",
       "2      Beverage            Green Tea              3             243   \n",
       "3      Beverage           Cappuccino              1             174   \n",
       "4       Dessert           Cheesecake              4             175   \n",
       "\n",
       "   total_bill  cost_price  profit payment_mode time_of_day  temperature_c  \\\n",
       "0         980      771.03  208.97         Cash     Morning           34.9   \n",
       "1         402      267.03  134.97         Card     Evening           25.3   \n",
       "2         729      519.16  209.84         Cash     Evening           29.0   \n",
       "3         174      105.44   68.56         Card     Evening           25.7   \n",
       "4         700      559.49  140.51         Card   Afternoon           26.8   \n",
       "\n",
       "  day_of_week  customer_rating  discount_percent  final_amount  \\\n",
       "0      Sunday              3.1                15        833.00   \n",
       "1    Thursday              3.0                 0        402.00   \n",
       "2     Tuesday              4.8                 5        692.55   \n",
       "3   Wednesday              4.8                 0        174.00   \n",
       "4     Tuesday              4.4                15        595.00   \n",
       "\n",
       "     special_event staff_id day_type  cumulative_sales_outlet  \n",
       "0  Weekend Special     ST11  Weekend                   833.00  \n",
       "1              NaN      ST4  Weekday                   402.00  \n",
       "2  Weekend Special     ST22  Weekday                   692.55  \n",
       "3     Diwali Offer     ST22  Weekday                   866.55  \n",
       "4      Coffee Fest      ST4  Weekday                   997.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying first five rows of the dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086c8b98-2b75-4932-9a70-13a1de6c5518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>outlet_location</th>\n",
       "      <th>outlet_manager</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_name</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>price_per_unit</th>\n",
       "      <th>total_bill</th>\n",
       "      <th>cost_price</th>\n",
       "      <th>profit</th>\n",
       "      <th>payment_mode</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temperature_c</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>final_amount</th>\n",
       "      <th>special_event</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>day_type</th>\n",
       "      <th>cumulative_sales_outlet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>ORD88057</td>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>Viman Nagar</td>\n",
       "      <td>Rohit Deshmukh</td>\n",
       "      <td>New</td>\n",
       "      <td>Beverage</td>\n",
       "      <td>Hot Chocolate</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>676</td>\n",
       "      <td>468.12</td>\n",
       "      <td>207.88</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Evening</td>\n",
       "      <td>25.8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4.9</td>\n",
       "      <td>15</td>\n",
       "      <td>574.6</td>\n",
       "      <td>Weekend Special</td>\n",
       "      <td>ST14</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>188004.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>ORD71910</td>\n",
       "      <td>2025-10-26</td>\n",
       "      <td>Viman Nagar</td>\n",
       "      <td>Rohit Deshmukh</td>\n",
       "      <td>Tourist</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Brownie</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>113.79</td>\n",
       "      <td>57.21</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Night</td>\n",
       "      <td>32.5</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>Coffee Fest</td>\n",
       "      <td>ST20</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>188175.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>ORD13597</td>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>Kothrud</td>\n",
       "      <td>Arjun Mehta</td>\n",
       "      <td>Tourist</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Pasta</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>648</td>\n",
       "      <td>516.21</td>\n",
       "      <td>131.79</td>\n",
       "      <td>Card</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>32.7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5</td>\n",
       "      <td>615.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST16</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>175690.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>ORD37000</td>\n",
       "      <td>2025-10-18</td>\n",
       "      <td>Koregaon Park</td>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>New</td>\n",
       "      <td>Snack</td>\n",
       "      <td>French Fries</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>702</td>\n",
       "      <td>515.19</td>\n",
       "      <td>186.81</td>\n",
       "      <td>Card</td>\n",
       "      <td>Morning</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10</td>\n",
       "      <td>631.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST10</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>190355.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>ORD86916</td>\n",
       "      <td>2025-10-22</td>\n",
       "      <td>Kothrud</td>\n",
       "      <td>Arjun Mehta</td>\n",
       "      <td>New</td>\n",
       "      <td>Beverage</td>\n",
       "      <td>Hot Chocolate</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>896</td>\n",
       "      <td>704.06</td>\n",
       "      <td>191.94</td>\n",
       "      <td>Card</td>\n",
       "      <td>Evening</td>\n",
       "      <td>25.2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>851.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST11</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>176541.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id        date outlet_location  outlet_manager customer_type  \\\n",
       "1995  ORD88057  2025-10-03     Viman Nagar  Rohit Deshmukh           New   \n",
       "1996  ORD71910  2025-10-26     Viman Nagar  Rohit Deshmukh       Tourist   \n",
       "1997  ORD13597  2025-10-14         Kothrud     Arjun Mehta       Tourist   \n",
       "1998  ORD37000  2025-10-18   Koregaon Park     Amit Sharma           New   \n",
       "1999  ORD86916  2025-10-22         Kothrud     Arjun Mehta           New   \n",
       "\n",
       "     item_category      item_name  quantity_sold  price_per_unit  total_bill  \\\n",
       "1995      Beverage  Hot Chocolate              4             169         676   \n",
       "1996       Dessert        Brownie              1             171         171   \n",
       "1997         Snack          Pasta              4             162         648   \n",
       "1998         Snack   French Fries              3             234         702   \n",
       "1999      Beverage  Hot Chocolate              4             224         896   \n",
       "\n",
       "      cost_price  profit payment_mode time_of_day  temperature_c day_of_week  \\\n",
       "1995      468.12  207.88         Cash     Evening           25.8      Friday   \n",
       "1996      113.79   57.21         Cash       Night           32.5      Sunday   \n",
       "1997      516.21  131.79         Card   Afternoon           32.7     Tuesday   \n",
       "1998      515.19  186.81         Card     Morning           30.0    Saturday   \n",
       "1999      704.06  191.94         Card     Evening           25.2   Wednesday   \n",
       "\n",
       "      customer_rating  discount_percent  final_amount    special_event  \\\n",
       "1995              4.9                15         574.6  Weekend Special   \n",
       "1996              3.8                 0         171.0      Coffee Fest   \n",
       "1997              3.1                 5         615.6              NaN   \n",
       "1998              3.2                10         631.8              NaN   \n",
       "1999              3.0                 5         851.2              NaN   \n",
       "\n",
       "     staff_id day_type  cumulative_sales_outlet  \n",
       "1995     ST14  Weekday                188004.30  \n",
       "1996     ST20  Weekend                188175.30  \n",
       "1997     ST16  Weekday                175690.50  \n",
       "1998     ST10  Weekend                190355.85  \n",
       "1999     ST11  Weekday                176541.70  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying last five rows of the dataframe\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ee5ecb-7c6d-425a-8135-ecc8cb529048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_id', 'date', 'outlet_location', 'outlet_manager', 'customer_type', 'item_category', 'item_name', 'quantity_sold', 'price_per_unit', 'total_bill', 'cost_price', 'profit', 'payment_mode', 'time_of_day', 'temperature_c', 'day_of_week', 'customer_rating', 'discount_percent', 'final_amount', 'special_event', 'staff_id', 'day_type', 'cumulative_sales_outlet']\n"
     ]
    }
   ],
   "source": [
    "# Displaying list of column names\n",
    "\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac446b-148d-4c64-a13c-e35cf5e5bd73",
   "metadata": {},
   "source": [
    "#### **Column Description**\n",
    "- **`order_id`** – Unique id for each order.\n",
    "- **`date`** – Date when the order was placed.\n",
    "- **`outlet_location`** – Location or branch of the outlet where the sale occurred.\n",
    "- **`outlet_manager`** – Name  of the manager handling that outlet.\n",
    "- **`customer_type`** – Type of customer (e.g., regular, new, member).\n",
    "- **`item_category`** – Category to which the sold item belongs.\n",
    "- **`item_name`** – Name of the product or item sold.\n",
    "- **`quantity_sold`** – Number of units of the item sold in the order.\n",
    "- **`price_per_unit`** – Selling price of one unit of the item.\n",
    "- **`total_bill`** – Total amount before discount and taxes.\n",
    "- **`cost_price`** – Original cost of the item to the outlet.\n",
    "- **`profit`** – Profit earned from the order or item sale.\n",
    "- **`payment_mode`** – Mode of payment used (e.g., cash, card, UPI).\n",
    "- **`time_of_day`** – Time slot of the sale (e.g., morning, afternoon, evening).\n",
    "- **`temperature_c`** – Temperature in Celsius at the time of the sale.\n",
    "- **`day_of_week`** – Day on which the sale occurred (e.g., Monday, Friday).\n",
    "- **`customer_rating`** – Rating given by the customer after purchase.\n",
    "- **`discount_percent`** – Discount percentage applied on the bill.\n",
    "- **`final_amount`** – Final payable amount after discount.\n",
    "- **`special_event`** – Indicates if the sale occurred during any special event or festival.\n",
    "- **`staff_id`** – Identifier of the staff member who processed the order.\n",
    "- **`day_type`** – Type of day (e.g., weekday, weekend, holiday).\n",
    "- **`cumulative_sales_outlet`** – Running total of all sales for the outlet up to that date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33b8e2-fcf1-401c-bffb-8e8e635db53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a0e63b34404215a338ff53754c0640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/23 [00:00<00:02,  7.61it/s]\u001b[A\n",
      " 22%|██▏       | 5/23 [00:00<00:00, 20.84it/s]\u001b[A\n",
      " 52%|█████▏    | 12/23 [00:00<00:00, 37.60it/s]\u001b[A\n",
      " 70%|██████▉   | 16/23 [00:00<00:00, 31.66it/s]\u001b[A\n",
      "100%|██████████| 23/23 [00:00<00:00, 35.41it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3776256de0a14daebaf6d734abc29fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating profile report before cleaning the dataset\n",
    "\n",
    "Profile = ProfileReport(df)\n",
    "Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cae7b-bc21-437f-87f7-067e937fdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying some random samples from the dataset\n",
    "\n",
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbe5c9-04ba-48f7-94a3-fb31260086ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying datatypes of columns\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56baec63-b8a5-400e-8b92-21c3cc3a2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here datatype of date is object, so we will convert it to datetime \n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f697f-4ad2-4b31-8699-c34c879c42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting columns from the date\n",
    "\n",
    "# Creating new features Year, Month, Day, Weekday, Weekend from 'Date' feature\n",
    "df['Year'] = df['date'].dt.year       # year from the date\n",
    "df['Month'] = df['date'].dt.month          # month from the date\n",
    "df['Day'] = df['date'].dt.day          # day number from the date\n",
    "df['IsWeekend'] = df['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)     # isweekend or not(yes or no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ef8b3-aec1-4b3a-b14e-61d2ad8fefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now here we are removing three columns order_id, staff_id and outlet_manager because they are not important or useful for our regression models and they will not influence our target column\n",
    "\n",
    "# Dropping 'order_id'\n",
    "df.drop(columns='order_id', axis=1, inplace=True)\n",
    "\n",
    "# Dropping 'staff_id'\n",
    "df.drop(columns='staff_id', axis=1, inplace=True)\n",
    "\n",
    "# Dropping 'outlet_manager'\n",
    "df.drop(columns='outlet_manager', axis=1, inplace=True)\n",
    "\n",
    "# Also we have extracted new columns from the column 'date' so we can drop column date\n",
    "df.drop(columns='date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81010503-09fe-4667-8626-52efd9cdb562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displcaying shape of the dataframe\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79591a7-9da5-464e-b11d-59b66c8e9b8e",
   "metadata": {},
   "source": [
    "**Their are 2000 records and 20 columns present in the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b11bfb-a4d0-4b5b-a0eb-a7e47a58b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking total number of missing values present in every column of the dataset\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b03e24-9a37-4f9f-be12-af4a0ffe04c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Their are 1407 missing values are present in 'special_event' column, so we will fill it will keyword 'unknown'\n",
    "\n",
    "df['special_event'] = df['special_event'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e3ff-c3fa-46c6-be01-24fc8f47c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values again after filling them\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b84755-2aaa-47fb-bd3f-7e4eb4dd304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking total number of duplicate records present in the dataset\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b57f2f-6330-486b-a68a-2519ce1f4379",
   "metadata": {},
   "source": [
    "**Dataset has now no missing values and duplicate records.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cf566-32ef-4219-b3e8-1653637d1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting statistical summary of numerical columns\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b060af-df23-4686-bdd6-70b1e69b3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting statistical summary of catgorical columns\n",
    "\n",
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b91d5-d75f-4d44-8ecf-ec9ff34e0b9a",
   "metadata": {},
   "source": [
    "### **Summary of categorical columns -**\n",
    "#### **`Outlet Location`**\n",
    "- It has 5 unique categories.\n",
    "- Top category is 'Koregaon Park' with a frequency 428.\n",
    "#### **`Customer Type`**\n",
    "- It has 3 unique categories.\n",
    "- Top category is 'Tourist' with a frequency 675.\n",
    "#### **`Item Category`**\n",
    "- It has 3 unique categories.\n",
    "- Top category is 'Beverage' with a frequency 696.\n",
    "#### **`Item Name`**\n",
    "- It has 17 unique categories.\n",
    "- Top category is 'Ice Cream' with a frequency 145.\n",
    "#### **`Payment Mode`**\n",
    "- It has 3 unique categories.\n",
    "- Top category is 'Card' with a frequency 683.\n",
    "#### **`Time of day`**\n",
    "- It has 4 unique categories.\n",
    "- Top category is 'Morning' with a frequency 524.\n",
    "#### **`Day of week`**\n",
    "- It has 7 unique categories.\n",
    "- Top category is 'Wednesday' with a frequency 324.\n",
    "#### **`Special Event`**\n",
    "- It has 4 unique categories.\n",
    "- Top category is 'Unknown' with a frequency 1407.\n",
    "#### **`Day Type`**\n",
    "- It has 2 unique categories.\n",
    "- Top category is 'weekday' with a frequency 1483."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53808e6e-736b-4c18-b4ce-23c5a46c28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two lists one for all categorical columns and another for numerical columns\n",
    "\n",
    "# List of categorical columns\n",
    "cat_col = ['outlet_location', 'customer_type', 'item_category', 'item_name', 'payment_mode', 'time_of_day', 'special_event', 'day_type', 'day_of_week','Year', 'Month', 'Day', 'IsWeekend']\n",
    "\n",
    "# List of numerical columns\n",
    "num_col =  ['quantity_sold', 'price_per_unit', 'total_bill','cost_price', 'profit', 'cumulative_sales_outlet', 'customer_rating', 'discount_percent', 'final_amount','cumulative_sales_outlet']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd6b38-7483-4fe4-8eac-34f2d3147300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting no of unique values in categorical column\n",
    "\n",
    "for col in cat_col:\n",
    "    print(f'\\nNo of unique values in {col} column are :')\n",
    "    print(df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14dc9b-1f48-4568-9fcf-9c4b046e1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting no of unique values in numerical column\n",
    "\n",
    "for col in num_col:\n",
    "    print(f'\\nNo of unique values in {col} column are :')\n",
    "    print(df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b7732-f6d2-42ff-a599-2f87efb5b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting unique values in categorical column\n",
    "\n",
    "for col in cat_col:\n",
    "    print(f'\\nUnique values in {col} column are :')\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e41b01-13aa-40a2-a3e6-f9f8340af9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting value counts of categorical columns\n",
    "\n",
    "for col in cat_col:\n",
    "    counts = df[col].value_counts()\n",
    "    print(f'\\nValue_counts for {col} column :')\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1cce8-fe30-4011-afa7-7eb0446a5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting highest value for each numerical column\n",
    "\n",
    "for column in num_col:\n",
    "    print(f'\\nMax value of {column} column is :')\n",
    "    print(df[column].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9de44a-1b27-42c3-9d08-f46f445a805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting lowest value for each numerical column\n",
    "\n",
    "for column in num_col:\n",
    "    print(f'\\nMin value of {column} column is :')\n",
    "    print(df[column].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7e128b-f846-4d44-b760-5e206ee820a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting top(most frequent) value of each categorical feature\n",
    "\n",
    "for col in cat_col:\n",
    "    print(f'\\nTop value of {column} column is :')\n",
    "    print(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e20f8-decc-4dd3-93e9-6436260905fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking skewness or shape of the data\n",
    "\n",
    "for col in num_col:\n",
    "    skew = df[col].skew()\n",
    "    print(f\"The skewness of column '{col}' is {round(skew,3)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88614328-729e-4af5-b9dd-efcc53aecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns for pie charts\n",
    "\n",
    "# List of categorical columns\n",
    "cat_col = ['outlet_location', 'customer_type', 'item_category', 'item_name', 'payment_mode', 'time_of_day', 'special_event', 'day_type', 'day_of_week']\n",
    "\n",
    "custom_colors = ['#008080', '#66ffff', '#00cccc','#009999']\n",
    "\n",
    "# creating 6 rows and 3 columns plots in subplot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(22, 18))\n",
    "\n",
    "# Change axes to 1D list so loop is easy\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Go through each column in list\n",
    "for i, col in enumerate(cat_col):\n",
    "    # value_counts\n",
    "    counts = df[col].value_counts()\n",
    "\n",
    "    # Push out the biggest slice\n",
    "    explode = [0.05 if v == counts.max() else 0 for v in counts]\n",
    "\n",
    "    # Make pie chart\n",
    "    axes[i].pie(counts,\n",
    "                labels=counts.index,     # labels for each slice\n",
    "                autopct='%1.1f%%',       # show percentage upto one decimal point\n",
    "                colors=custom_colors,   \n",
    "                explode=explode)         # push biggest slice\n",
    "\n",
    "    # Title for pie chart\n",
    "    axes[i].set_title(f'Distribution of {col}', fontsize=22, fontweight='bold')\n",
    "\n",
    "    # it Keep pie chart round\n",
    "    axes[i].axis('equal')\n",
    "\n",
    "# Hide extra empty plots\n",
    "for j in range(len(cat_col), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Adjust space between plots and overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show all charts\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e4eaf-2032-484a-82de-6cb14c710928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Interquartile range to check outliers \n",
    "\n",
    "for col in num_col:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "    if not outliers.empty:\n",
    "        print(f\"Column '{col}' has {len(outliers)} outliers.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' has no outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac931c76-6b1a-43ad-9c47-f493f8edbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting boxplot to detect outliers \n",
    "\n",
    "# Create a figure with 7 rows and 2 columns of subplot\n",
    "# Axes is individual plot where we plot boxplot here\n",
    "fig, axes = plt.subplots(5, 2, figsize=(15, 20))\n",
    "\n",
    "# Flatten the 2D array of axes into a 1D array so we can loop easily\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate throught each column with position which helps to pick up correct subplot\n",
    "for i, col in enumerate(num_col):\n",
    "    sns.boxplot(x=df[col], ax=axes[i],palette=\"Blues\")\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "# Adjusting the layout so that the plots don't overlap with each other\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda2767-330b-46ba-a5a5-931bb7c31b96",
   "metadata": {},
   "source": [
    "#### **`Distribution of quantity sold`** -\n",
    "- The middle 50% of quantity sold are between around 1 and 3.\n",
    "- The median rented bike count is near 500.\n",
    "- The lower whisker is 1 and the upper whisker is 4.\n",
    "- There are no outliers present in quantity sold column.\n",
    "\n",
    "#### **`Distribution of price per unit`** -\n",
    "- The middle 50% values of price per unit are between around 150 and 250.\n",
    "- The median price per unit value is near 200.\n",
    "- The lower whisker is near -18 and the upper whisker is near 40.\n",
    "- There are no outliers present in Temperature column.\n",
    "\n",
    "#### **`Distribution of total bill`** -\n",
    "- The middle 50% values of total bill are between around 300 and 700.\n",
    "- The median value of total bill is near 450.\n",
    "- The lower whisker is near 100 and the upper whisker is near 1200.\n",
    "- There are no outliers present in total bill column.\n",
    "\n",
    "#### **`Distribution of cost price`** -\n",
    "- The middle 50% values of cost price are between around 200 and 500.\n",
    "- The median cost price is near 300.\n",
    "- The lower whisker is near 100 and the upper whisker is near 900.\n",
    "- **There are few high outliers present in wind cost price column.**\n",
    "\n",
    "#### **`Distribution of profit`** -\n",
    "- The middle 50% values of profit are between around 80 and 210.\n",
    "- The median value of profit is near 130.\n",
    "- The lower whisker is 0 and the upper whisker is near 400.\n",
    "- **There are extreme high outliers present in profit column.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111debb3-44a9-46c9-8d70-adf7b4e72f87",
   "metadata": {},
   "source": [
    "**`In this dataset 3 outliers in cost_price column and 36 outliers in profit.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03827614-25b4-4ac7-8d52-e6e53918706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to remove the outliers because no of outliers are very few\n",
    "\n",
    "for col in num_col:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "    df = df[(df[col] >= lower) & (df[col] <= upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e936027-0079-4d99-b47d-b06dcd743837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting boxplot to detect outliers \n",
    "\n",
    "# Create a figure with 7 rows and 2 columns of subplot\n",
    "# Axes is individual plot where we plot boxplot here\n",
    "fig, axes = plt.subplots(5, 2, figsize=(15, 20))\n",
    "\n",
    "# Flatten the 2D array of axes into a 1D array so we can loop easily\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate throught each column with position which helps to pick up correct subplot\n",
    "for i, col in enumerate(num_col):\n",
    "    sns.boxplot(x=df[col], ax=axes[i], palette=\"Blues\")\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "# Adjusting the layout so that the plots don't overlap with each other\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2071d6-50ae-4f48-b305-7206b0e96af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are using log transformation to handle remaining outliers\n",
    "# Log Transformation is a technique used to reduce the effect of extreme values (outliers) and make skewed data more normal.\n",
    "\n",
    "df['cost_price'] = np.log1p(df['cost_price'])\n",
    "df['profit'] = np.log1p(df['profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128746c2-e674-4d3e-af21-e5e232eabba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Interquartile range to check outliers after handling \n",
    "\n",
    "for col in num_col:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "    if not outliers.empty:\n",
    "        print(f\"Column '{col}' has {len(outliers)} outliers.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' has no outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc95f0-7f2b-41ed-b3e5-9230627be7fd",
   "metadata": {},
   "source": [
    "**`Now dataset has no missing values, no duplicate records and no outliers.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62311ac-deac-4b37-8eed-f2cd3dc07cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating profile report after cleaning the dataset\n",
    "\n",
    "Profile = ProfileReport(df)\n",
    "Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6110ce7-d63e-4258-8d4b-819e76f35cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying countplot for categorical columns\n",
    "\n",
    "# List of categorical columns\n",
    "cat_col = ['outlet_location', 'customer_type', 'item_category', 'payment_mode', 'time_of_day', 'special_event', 'day_type', 'day_of_week','Year', 'Month', 'Day', 'IsWeekend']\n",
    "\n",
    "# Create subplots: 3 rows, 3 columns\n",
    "fig, axes = plt.subplots(6, 2 , figsize=(22, 40)) \n",
    "\n",
    "# Flatten the 2D array of axes to 1D\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each categorical column\n",
    "for i, col in enumerate(cat_col):\n",
    "    if col != 'iteam_name':\n",
    "        sns.countplot(data=df, x=col, palette=\"Blues\", ax=axes[i])\n",
    "        axes[i].set_title(f'{col} Count', fontweight='bold', fontsize=14)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=50)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc94ca-f4d0-40c6-8cf2-983710cfdf44",
   "metadata": {},
   "source": [
    "#### **`Outlet Location Count`**\n",
    "- Here are five unique outlets and all of have above 250 orders count.\n",
    "- Top catgory is Koregaon Park having more than 400 orders count.\n",
    "#### **`Customers Type Count`**\n",
    "- Here are three types of customers(regular, tourist, new) and all of have count above 600.\n",
    "#### **`Item Category Count`**\n",
    "- Here are three item categories which are snack, beverage and dessert and all of this have above 600 count.\n",
    "- Top category is beverage with near count of 650.\n",
    "#### **`Payment Mode Count`**\n",
    "- Here are three iunique payment modes(cash, card, upi).\n",
    "- Customers done payments using all of this three modes with count above 600.\n",
    "- Top mode is card with near count of 650\n",
    "#### **`Time of the day Count`**\n",
    "- Customers visit caffe's to morning, afternoon, evening as well as night and all have count above 450.\n",
    "- top time of the day is morning with the frequency above 500 orders count.\n",
    "#### **`Special Event Count`**\n",
    "- Above 1300 events are unknown.\n",
    "- Weekend special, diwali offer, coffee fest have count below 200.\n",
    "#### **`Day Type Count`**\n",
    "- Near 500 days are weekends and above 1400 days are weekdays.\n",
    "#### **`Day of Week Count`**\n",
    "- Thursday, Wednesday and Friday orders count is above 300.\n",
    "- Sunday, Tuesday, Monday and Saturday orders count is below 250.\n",
    "#### **`Year Count`**\n",
    "- All of this records of the year 2024.\n",
    "#### **`Month Count`**\n",
    "- All of this records of the month October.\n",
    "#### **`Days Count`**\n",
    "- All of this 31 days have above 60 orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6cb50-ef1c-47a1-9ad2-f51fb6f24f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot for food items\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.countplot(data=df, x='item_name', palette=\"Blues\")\n",
    "plt.xticks(rotation=50)\n",
    "plt.title('Count of Food Items',fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1968f95-7e5e-4ac9-bcdd-c74c9ecc7816",
   "metadata": {},
   "source": [
    "#### **`Count of Food item`**\n",
    "- Above 140 orders have food item Ice Cream and Ice Latte.\n",
    "- All of this food items are ordered in above 60 orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600288ea-9226-4b03-b103-73068d5bf425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d6a6a-4f8d-4f6d-b914-1d549528e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting scatterplot of numerical columns with target column\n",
    "\n",
    "# List of numerical columns\n",
    "num_col =  ['quantity_sold', 'price_per_unit', 'total_bill','cost_price','temperature_c' ,'profit','customer_rating', 'discount_percent', 'final_amount']\n",
    "        \n",
    "fig, axes = plt.subplots(3,3, figsize=(15, 10))  \n",
    "axes = axes.flatten() \n",
    "\n",
    "for i, col in enumerate(num_col):\n",
    "    sns.scatterplot(x=df[col], y=df['cumulative_sales_outlet'], ax=axes[i])\n",
    "    axes[i].set_title(f'{col} vs cumulative sales outlet')\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1440f50-24fb-4e22-9205-cd10e67f5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  # import LabelEncoder from sklearn.preprocessing\n",
    "le = LabelEncoder()  # initialize label encoder\n",
    "\n",
    "# List of categorical columns\n",
    "cat_col = ['outlet_location', 'customer_type','item_name', 'item_category', 'payment_mode', 'time_of_day', 'special_event', 'day_type', 'day_of_week','Year', 'Month', 'Day', 'IsWeekend']\n",
    "\n",
    "# Apply label encoding to each categorical column\n",
    "for col in cat_col:\n",
    "    df[col] = le.fit_transform(df[col])  # Convert categories to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd3c73-4e14-464e-9e53-fece1eaeaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()    # now categorical columns are converted into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6366560-ee4d-40de-9784-d722030ab80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fac453-9511-4efd-80bd-7f5fc33ab04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying correlation heatmap between all numerical columns\n",
    "\n",
    "plt.figure(figsize=(22, 20))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='Blues')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c8ec3-1e8a-4e50-83c8-4fbc8c206398",
   "metadata": {},
   "source": [
    "### **`Top Positive Correlations`**\n",
    "- cost price is highly correlated with final amount, quantity sold, price per unit, profit, total bill.\n",
    "- total bill, cost price is highly correlated with final payment.\n",
    "- profit is highly correlated with price per unit.\n",
    "- quantity sold is highly correlated with total bill, cost price, profit.\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad29d3b-5fa6-4aa3-8636-2abbcbacf466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are using Robust Scaling because in this datset their are lots of outliers present\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler   # importing robust scaler from skleran.preprocessing\n",
    "scaler = RobustScaler()                     # initializing robust scaler\n",
    "\n",
    "# List of categorical columns\n",
    "# cat_col = ['outlet_location', 'customer_type','item_name', 'item_category', 'payment_mode', 'time_of_day', 'special_event', 'day_type', 'day_of_week','Year', 'Month', 'Day', 'IsWeekend']\n",
    "\n",
    "# List of columns with numerical values\n",
    "cols = ['quantity_sold','price_per_unit','total_bill','cost_price','profit','final_amount']\n",
    "\n",
    "# Applying robust scaler to each numerical columns\n",
    "df[cols] = scaler.fit_transform(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b0915-0734-4354-bb6f-dcf6e22372d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52a5b3-47de-4213-ba77-0b21c5ec0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # import train_test_split to split the dataset into testing and training datasets\n",
    "\n",
    "# Defining X and y\n",
    "X = df.drop('cumulative_sales_outlet', axis=1)  # all columns except the target column\n",
    "y = df['cumulative_sales_outlet']               # only target column\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbfd2c5-d5ac-46da-b5ce-07274431c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, MSE: {mse}, RMSE: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c72cb-428e-4ab8-8c3b-629aef54466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "\n",
    "gbr_model = GradientBoostingRegressor(\n",
    "    n_estimators=150,    \n",
    "    learning_rate=0.05, \n",
    "    max_depth=8,            # Maximum depth of each tree\n",
    "    min_samples_split=10,   # Minimum samples required to split a node\n",
    "    min_samples_leaf=5,     # Minimum samples required at a leaf\n",
    "    random_state=42\n",
    ")\n",
    "gbr_model.fit(X_train, y_train)\n",
    "y_pred_gbr = gbr_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred_gbr)\n",
    "mse = mean_squared_error(y_test, y_pred_gbr)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred_gbr)\n",
    "print(f\"Gradient Boosting Regressor Results:\")\n",
    "print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e89faa-cdac-4438-92bd-e2224e79f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, MSE: {mse}, RMSE: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44dfcfd-7671-466e-b3eb-92812857dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred_dt)\n",
    "mse = mean_squared_error(y_test, y_pred_dt)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Regressor Results:\")\n",
    "print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc032bd3-4c93-406d-84f1-8f12c07fe7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple linear Regression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, MSE: {mse}, RMSE: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482ef76-417b-42df-8ffa-ba19924adaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing all models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Training and evaluating each model\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    # Training  model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Making predictions\n",
    "    y_pred_model = model.predict(X_test)\n",
    "    \n",
    "    # Evaluating metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred_model)\n",
    "    mse = mean_squared_error(y_test, y_pred_model)\n",
    "    rmse = mse ** 0.5\n",
    "    r2 = r2_score(y_test, y_pred_model)\n",
    "    \n",
    "    # Storing results\n",
    "    results[model_name] = {\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2\n",
    "    }\n",
    "\n",
    "# Displaying results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.sort_values(by=\"R²\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
